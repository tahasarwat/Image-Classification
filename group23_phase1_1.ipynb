{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpn9k3BV1X2s"
      },
      "source": [
        "# CS331 - Spring 2022 - Phase 1 [10%]\n",
        "\n",
        "*__Submission Guidelines:__* \n",
        "- Naming convention for submission of this notebook is `groupXX_phase1.ipynb` where XX needs to be replaced by your group number. For example: group 1 would rename their notebook to `group01_phase1.ipynb`\n",
        "- Only the group lead is supposed to make the submission\n",
        "- All the cells <b>must</b> be run once before submission. If your submission's cells are not showing the results (plots etc.), marks wil be deducted\n",
        "- Only the code written within this notebook will be considered while grading. No other files will be entertained\n",
        "- You are advised to follow good programming practies including approriate variable naming and making use of logical comments \n",
        "\n",
        "Please note that your notebooks will be checked against submissions from last year's course offering for plagiarism. The university honor code should be maintained. Any violation, if found, will result in disciplinary action.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9cjup_91X2_"
      },
      "source": [
        "#### <b>Introduction</b> \n",
        "This is the first of the three phases of this offering's project. To give an overview of this phase, we will essentially be building everything from scratch. The datasets that we will be using for this project are the MNIST and the Fashion_MNIST dataset. <b> This notebook will focus on the MNIST dataset. </b> \n",
        "\n",
        "The MNIST dataset has a training set of 60,000 examples, and a test set of 10,000 examples. These examples consist of hand-written digits that belong to ten different classes (numbers 1 through 10). The given images have been size-normalized and centered in a fixed-size image. It would also be highly advisable to go through [this link](http://yann.lecun.com/exdb/mnist/) the information provided in this link to fully understand this dataset.\n",
        "\n",
        "You will begin by pre-processing the already-loaded dataset in this notebook followed by from-scratch implementation of a Neural Network (NN). Once done, you will have to tweak the hyperparameters (such as learning rate, number of epochs etc.) to get the best results for your NN's implementation\n",
        "\n",
        "###### <b>You will strictly be using for-loops fort this phase's implementation of NN (unless specified otherwise in the sub-section)\n",
        "\n",
        "###### Modification of the provided code without prior discussion with the TAs will result in a grade deduction </b>\n",
        "\n",
        "---\n",
        "\n",
        "###### <b>Side note</b>\n",
        "The `plot_model` method will only work if you have the `pydot` python package installed along with [Graphviz](https://graphviz.gitlab.io/download/). If you do not wish to use this then simply comment out the import for `pydot`\n",
        "\n",
        "###### <b>Need Help?</b>\n",
        "If you need help, please refer to the course staff ASAP and do not wait till the last moment as they might not be available on very short notice close to deadlines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5m1T5nJ6WH3"
      },
      "source": [
        "#### <b>Before You Begin</b>\n",
        "\n",
        "Skeleton code is provided to get you started. The main methods that you need to implement correspond to the four steps of the training process of a NN which are as follows:\n",
        "1. Initialize variables and initialize weights\n",
        "2. Forward pass\n",
        "3. Backward pass AKA Backpropagation\n",
        "4. Weight Update AKA Gradient Descent\n",
        "\n",
        "__Look for comments in the code to see where you are supposed to write your code__ \n",
        "\n",
        "A `fit` function is what combines the previous three functions and overall trains the network to __fit__ to the provided training examples. The provided `fit` methods requires all the four steps of the training process to be working correctly. The function has been setup in a way that it expects the above four methods to take particular inputs and return particular outputs. __You are supposed to work within this restriction__ \n",
        "\n",
        "\n",
        "\n",
        "__To see if your model is working correctly, you need to make sure that your model loss is going down during training__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-30T14:39:17.671980Z",
          "start_time": "2019-01-30T14:38:40.137027Z"
        },
        "id": "UPL8Ut1u1X2-"
      },
      "outputs": [],
      "source": [
        "# Making all the necessary imports here\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "from IPython.display import Image\n",
        "import pydot\n",
        "from tqdm import tqdm_notebook\n",
        "import seaborn as sns\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from google.colab import drive\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-y-6i2TL1X3C"
      },
      "outputs": [],
      "source": [
        "# This function will be used to plot the confusion matrix at the end of this notebook\n",
        "\n",
        "def plot_confusion_matrix(conf_mat):\n",
        "    classes = ['1','2','3','4','5','6','7','8','9','10']\n",
        "    df_cm = pd.DataFrame(conf_mat,classes,classes)\n",
        "    plt.figure(figsize=(15,9))\n",
        "    sns.set(font_scale=1.4)\n",
        "    sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})\n",
        "    plt.show()\n",
        "\n",
        "class_labels = ['1','2','3','4','5','6','7','8','9','10']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-30T14:36:37.383767Z",
          "start_time": "2019-01-30T14:36:37.333537Z"
        },
        "id": "xU_yqbc31X2_"
      },
      "outputs": [],
      "source": [
        "# Enter group lead's roll number here. This will be used for plotting purposes\n",
        "\n",
        "rollnumber = 24100043"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHrz4X069_6D"
      },
      "source": [
        "#### __Loading and Pre-processing the MNIST dataset__\n",
        "\n",
        "The MNIST dataset has been already loaded using the imported keras APIs. You have to pre-process the given training and testing samples according to the implementation of your NN. It is recommended that you print the given matrices to figure out how to go about pre-processing. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nBj9_sg9-Auu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb327c9-cc67-45da-8ebc-4b86a58de348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training samples matrix: (60000, 28, 28)\n",
            "Size of testing samples matrix: (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "# Loading the dataset using keras APIs\n",
        "''' \n",
        "x_train = variable to store training images\n",
        "y_train = variable to store training images' labels\n",
        "x_test = variable to store test images\n",
        "y_test = variable to store test images' labels\n",
        "'''\n",
        "\n",
        "classes = 10  # do not change this\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Sizes of test and training samples\n",
        "print(\"Size of training samples matrix:\", x_train.shape)\n",
        "print(\"Size of testing samples matrix:\", x_test.shape)\n",
        "\n",
        "###### Code Here ######\n",
        "'''Hint: You will have to normalize the given matrices'''\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#x_test = x_test.reshape(x_test.shape[0], image_vector_size) # not sure if test flatten \n",
        "\n",
        "\n",
        "#one hot encode y_train and y_test\n",
        "y_train = np_utils.to_categorical(y_train, classes) #shape(60000,10) 60000 observation and 10 possible output label\n",
        "y_test = np_utils.to_categorical(y_test, classes)\n",
        "\n",
        "#input is 28x28 image which will be flattened to 784 size vector in skeleton code. have 60000 such observation\n",
        "#784 inputs observation 60000\n",
        "# 10 output classes 60000 observation so 10 nodes at output \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "a = np.array([[1, 3]])\n",
        "a=a.reshape(2,)\n",
        "print(a.shape)\n",
        "\n",
        "\n",
        "print(c*c)\n",
        "b = [[4, 1], [2, 2],[1,1]]\n",
        "x=np.matmul(b,a)\n",
        "print(x)\n",
        "\n",
        "n2=np.array([1,2,3])\n",
        "n1=np.array([5,6])\n",
        "n1=n1.reshape(1,2)\n",
        "x=np.dot(n2,n1)\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QxioHkgROKVI",
        "outputId": "6dfdd139-ca2c-472f-a9a1-b9cf8432399f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\na = np.array([[1, 3]])\\na=a.reshape(2,)\\nprint(a.shape)\\n\\n\\nprint(c*c)\\nb = [[4, 1], [2, 2],[1,1]]\\nx=np.matmul(b,a)\\nprint(x)\\n\\nn2=np.array([1,2,3])\\nn1=np.array([5,6])\\nn1=n1.reshape(1,2)\\nx=np.dot(n2,n1)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "QOxoQ-_B1X3B"
      },
      "source": [
        "#### __NN Implementation__\n",
        "Your implementation of NN needs to use the `sigmoid` activation function for the hidden layer(s) and the `softmax` activation function for the output layer. The NN model you will be creating here will consits of only three layers: 1 input layer, 1 hidden layer and 1 output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:25:17.044301Z",
          "start_time": "2019-01-27T01:25:16.984346Z"
        },
        "hidden": true,
        "id": "iP5ZI2Rs1X3C"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork():\n",
        "    \n",
        "    def matrix_mult(self,a,b):\n",
        "        row_a=a.shape[0]\n",
        "        row_b=b.shape[0]\n",
        "        col_b=b.shape[1]\n",
        "        prod= np.zeros((row_a, col_b))\n",
        "        for i in range(row_a): #rows of a\n",
        "   \n",
        "          for j in range(col_b): #col of b\n",
        "            for k in range(row_b): #row of b\n",
        "              prod[i][j]+= a[i][k]*b[k][j]\n",
        "        return prod\n",
        "\n",
        "    def transpose_mat(self,a):\n",
        "        row_a= a.shape[0]\n",
        "        col_a= a.shape[1]\n",
        "        trans= np.zeros((col_a,row_a))\n",
        "        for i in range(row_a):\n",
        "          for j in range(col_a):\n",
        "            trans[j][i]= a[i][j]\n",
        "        return trans\n",
        "    @staticmethod\n",
        "    \n",
        "    def cross_entropy_loss(y_pred, y_true):\n",
        "        ###### Code Here ######\n",
        "        #shape of y here is (60000,10)\n",
        "        total_loss= -(1/y_pred.shape[0])*np.sum(y_true*np.log(y_pred)) #over all nodes and all observation\n",
        "        return total_loss \n",
        "    \n",
        "    @staticmethod\n",
        "    def accuracy(y_pred, y_true):\n",
        "        ###### Code Here ######\n",
        "        \n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        ###### Code Here ######\n",
        "        e=np.exp(x)\n",
        "        act_x= e/np.sum(e)\n",
        "\n",
        "        # x here is z . we activate z\n",
        "        #and shape is(1,n) where n is number of nodes in that layer. It is just for one observation\n",
        "\n",
        "        return act_x\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        ###### Code Here ######\n",
        "        act_x= 1/(1+np.exp(-x))\n",
        "        #x here is z\n",
        "        #and shape is(1,n) where n is number of nodes in that layer. It is just for one observation\n",
        "        return act_x\n",
        "    def sigmoid_derivative(self,act):\n",
        "        derv= act*(1-act)\n",
        "        #shape act is(1,n) where n is number of nodes in that layer\n",
        "        return derv\n",
        "    def __init__(self, input_size, hidden_nodes, output_size):\n",
        "        '''Creates a Feed-Forward Neural Network.\n",
        "        The parameters represent the number of nodes in each layer (total 3). \n",
        "        Look at the inputs to the function'''\n",
        "        \n",
        "        self.num_layers = 3\n",
        "        self.input_shape = input_size\n",
        "        self.hidden_shape = hidden_nodes\n",
        "        self.output_shape = output_size\n",
        "        \n",
        "        self.weights_ = []\n",
        "        self.biases_ = []\n",
        "        self.__init_weights()\n",
        "    \n",
        "    def __init_weights(self):\n",
        "        '''Initializes all weights based on standard normal distribution and all biases to 0.'''\n",
        "        \n",
        "        ###### Code Here (Replace 'None' by appropriate values/variables) ######\n",
        "        \n",
        "        W_h = np.random.normal(size=(self.hidden_shape,self.input_shape))\n",
        "        b_h = np.zeros(shape=(self.hidden_shape,1))\n",
        "        #shape w_h=(n_h,x_input)\n",
        "        #shape b_h=(n_h,1)\n",
        "\n",
        "        W_o = np.random.normal(size=(self.output_shape,self.hidden_shape))\n",
        "        b_o = np.zeros(shape=(self.output_shape,1))\n",
        "        # shape w_o=(n_o,n_h)\n",
        "\n",
        "        #n_h is node in hidden layer and n_o is nodes in output layer\n",
        "\n",
        "        # self.weights_ becomes a list of np.arrays. 0th index has W_h and 1st index has W_o\n",
        "        self.weights_.append(W_h)  \n",
        "        self.weights_.append(W_o)  \n",
        "\n",
        "        # self.biases_ becomes a list of np.arrays. 0th index has b_h and 1st index has b_o\n",
        "        self.biases_.append(b_h)\n",
        "        self.biases_.append(b_o)\n",
        "\n",
        "    def forward_pass(self, input_data):\n",
        "        '''Executes the feed forward algorithm.\n",
        "        \"input_data\" is the input to the network in row-major form\n",
        "        Returns \"activations\", which is a list of all layer outputs (excluding input layer of course)'''\n",
        "        \n",
        "\n",
        "        #z_h= w_h*x + b_h\n",
        "        z_h= self.matrix_mult(self.weights_[0],self.transpose_mat(input_data))+self.biases_[0] #2d (n_h,1)\n",
        "        z_h= self.transpose_mat(z_h)# (1,n_h)\n",
        "        act_h= self.sigmoid(z_h) #(1,n_h)\n",
        "        \n",
        "        #z_o= w_o*act_h +b_o\n",
        "        z_o= self.matrix_mult(self.weights_[1],self.transpose_mat(act_h)) +self.biases_[1] #(n_o,1)\n",
        "        z_o= self.transpose_mat(z_o) #(1,n_o)\n",
        "        act_o= self.softmax(z_o) #(1,n_o)\n",
        "        activations= []\n",
        "        activations.append(act_h)\n",
        "        activations.append(act_o)\n",
        "        ###### Code Here ######\n",
        "        \n",
        "\n",
        "        return activations\n",
        "\n",
        "    def backward_pass(self, input,targets, layer_activations):\n",
        "        '''Executes the backpropogation algorithm.\n",
        "        \"targets\" is the ground truth/labels\n",
        "        \"layer_activations\" are the return value of the forward pass step\n",
        "        Returns \"deltas\", which is a list containing weight update values for all layers (excluding the input layer of course)'''\n",
        "        \n",
        "        ###### Code Here ######\n",
        "        w_h=self.weights_[0]\n",
        "        w_o=self.weights_[1]\n",
        "        b_h=self.biases_[0]\n",
        "        b_o=self.biases_[1]\n",
        "        a_h=layer_activations[0]\n",
        "        a_o=layer_activations[1]\n",
        "\n",
        "        \n",
        "        #dcost/dw_o= dcost/dz_o *dz_o/dw_o\n",
        "\n",
        "        dcost_dz_o= a_o-targets # shape(1,n_o) n_o output\n",
        "        dcost_dw_o= self.matrix_mult(self.transpose_mat(dcost_dz_o),a_h) #(n_o,n_h)\n",
        "        dcost_db_o= dcost_dz_o #(n_o,1)\n",
        "\n",
        "        #dcost/dw_h=dcost/dz_h *dz_h/dw_h\n",
        "        #dcost/dz_h=dcost/dz_o*dz_o/da_h\n",
        "        #dz_h/dw_h= x\n",
        "        dcost_dz_h=(self.matrix_mult(dcost_dz_o,w_o)) * self.sigmoid_derivative(a_h) # both are (1,n_h)\n",
        "        dcost_dw_h= self.matrix_mult(self.transpose_mat(dcost_dz_h),input) #(n_h,inputsize)\n",
        "        dcost_db_h= dcost_dz_h\n",
        "\n",
        "        deltas=[]\n",
        "        deltas.append(dcost_dw_h)\n",
        "        deltas.append(dcost_db_h)\n",
        "        deltas.append(dcost_dw_o)\n",
        "        deltas.append(dcost_db_o)\n",
        "\n",
        "        return deltas\n",
        "    \n",
        "    def weight_update(self, deltas, layer_inputs, lr):\n",
        "        '''Executes the gradient descent algorithm.\n",
        "        \"deltas\" is return value of the backward pass step\n",
        "        \"layer_inputs\" is a list containing the inputs for all layers (including the input layer)\n",
        "        \"lr\" is the learning rate'''\n",
        "        w_h=self.weights_[0]\n",
        "        w_o=self.weights_[1]\n",
        "        b_h=self.biases_[0]\n",
        "        b_o=self.biases_[1]\n",
        "        dcost_dw_h=deltas[0]\n",
        "        dcost_db_h=deltas[1]\n",
        "        dcost_dw_o=deltas[2]\n",
        "        dcost_db_o=deltas[3]\n",
        "        \n",
        "        w_h=w_h - lr*dcost_dw_h\n",
        "        b_h=b_h - lr*self.transpose_mat(dcost_db_h)\n",
        "        w_o=w_o - lr*dcost_dw_o\n",
        "        b_o=b_o - lr*self.transpose_mat(dcost_db_o)\n",
        "\n",
        "        self.weights_[0]=w_h\n",
        "        self.weights_[1]=w_o\n",
        "        self.biases_[0]=b_h\n",
        "        self.biases_[1]=b_o\n",
        "\n",
        "        ###### Code Here ######\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    ###### Do Not Change Anything Below this line in This Cell ######\n",
        "    \n",
        "    def fit(self, Xs, Ys, epochs, lr=1e-3):\n",
        "            history = []\n",
        "            for epoch in tqdm_notebook(range(epochs)):\n",
        "                num_samples = Xs.shape[0]\n",
        "                for i in range(num_samples):\n",
        "\n",
        "                    sample_input = Xs[i,:].reshape((1,self.input_shape))\n",
        "                    sample_target = Ys[i,:].reshape((1,self.output_shape))\n",
        "                    \n",
        "                    activations = self.forward_pass(sample_input)   # Call forward_pass function \n",
        "                    deltas = self.backward_pass(sample_input,sample_target, activations)    # Call backward_pass function  #edit adding sampleinput\n",
        "                    layer_inputs = [sample_input] + activations[:-1]\n",
        "                    \n",
        "                    # Call weight_update function \n",
        "                    self.weight_update(deltas, layer_inputs, lr)\n",
        "                \n",
        "                preds = self.predict(Xs)   # Call predict function \n",
        "                \n",
        "                current_loss = self.cross_entropy_loss(preds, Ys)\n",
        "                \n",
        "                if  epoch==epochs-1:\n",
        "                  confusion_mat=confusion_matrix(Ys.argmax(axis=1), preds.argmax(axis=1),labels=np.arange(10))  \n",
        "                  plot_confusion_matrix(confusion_mat)\n",
        "                  report = classification_report(Ys, np_utils.to_categorical(preds.argmax(axis=1),num_classes=classes), target_names=class_labels)\n",
        "                  print(report)\n",
        "                history.append(current_loss)\n",
        "            return history\n",
        "    \n",
        "    def predict(self, Xs):\n",
        "        '''Returns the model predictions (output of the last layer) for the given \"Xs\".'''\n",
        "        predictions = []\n",
        "        num_samples = Xs.shape[0]\n",
        "        for i in range(num_samples):\n",
        "            sample = Xs[i,:].reshape((1,self.input_shape))\n",
        "            sample_prediction = self.forward_pass(sample)[-1]\n",
        "            predictions.append(sample_prediction.reshape((self.output_shape,)))\n",
        "        return np.array(predictions)\n",
        "    \n",
        "    def evaluate(self, Xs, Ys):\n",
        "        '''Returns appropriate metrics for the task, calculated on the dataset passed to this method.'''\n",
        "        pred = self.predict(Xs)\n",
        "        return self.cross_entropy_loss(pred, Ys), self.accuracy(pred.argmax(axis=1), Ys.argmax(axis=1))\n",
        "    \n",
        "    def plot_model(self, filename):\n",
        "        '''Provide the \"filename\" as a string including file extension. Creates an image showing the model as a graph.'''\n",
        "        graph = pydot.Dot(graph_type='digraph')\n",
        "        graph.set_rankdir('LR')\n",
        "        graph.set_node_defaults(shape='circle', fontsize=0)\n",
        "        nodes_per_layer = [self.input_shape, self.hidden_shape, self.output_shape]\n",
        "        for i in range(self.num_layers-1):\n",
        "            for n1 in range(nodes_per_layer[i]):\n",
        "                for n2 in range(nodes_per_layer[i+1]):\n",
        "                    edge = pydot.Edge(f'l{i}n{n1}', f'l{i+1}n{n2}')\n",
        "                    graph.add_edge(edge)\n",
        "        graph.write_png(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "_200Z0dwE2Fq"
      },
      "outputs": [],
      "source": [
        "# These are what we call the hyperparameters (a.k.a Black Magic). You need to research on them and tweak them to see what generates the best result for you \n",
        "\n",
        "INPUT_SIZE = 28*28       # must be an int, this number represents the numeber of nodes/neurons in the input layer of the network\n",
        "HIDDEN_NODES = 32     # must be an int, this number represents the numeber of nodes/neurons in the only hidden layer of the network\n",
        "OUTPUT_SIZE = 10      # must be an int, this number represents the numeber of nodes/neurons in the output layer of the network\n",
        "EPOCH = 1      # must be an int\n",
        "LEARNING_RATE = 0.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "FRtc2Dzc2D_H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447,
          "referenced_widgets": [
            "edfd44368ce34b0baaf8e0d1a018905b",
            "fbc7aed21cf344a8b62d533486c990d0",
            "4b013811de1647f6a91b7b3f913d3f0f",
            "45f90d00f99c4e06a5e976e8d45e1394",
            "e638b9ca43874e5eae5d4b26118a4f54",
            "35249f8243fb43e780bbe956c5205779",
            "55388ce0810249ee92d46850aa5c3672",
            "f920be710ea64966abf1455e7e61ed70",
            "d4d9aa81c4064a27a984f06a41acb44a",
            "05dff9eb1af8463cbeb81d9b09e38997",
            "7a79e130635c4179bdb65534881fabda"
          ]
        },
        "outputId": "e4089b4b-7612-4b1a-a6a1-1cfea9def7d5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:190: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edfd44368ce34b0baaf8e0d1a018905b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-b5bdfae1539b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINPUT_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHIDDEN_NODES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Cross-entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Plot {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-8d0b9a260f83>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Xs, Ys, epochs, lr)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Call forward_pass function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Call backward_pass function  #edit adding sampleinput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m                     \u001b[0mlayer_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-8d0b9a260f83>\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(self, input, targets, layer_activations)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m#dz_h/dw_h= x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mdcost_dz_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcost_dz_o\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_h\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# both are (1,n_h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mdcost_dw_h\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcost_dz_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(n_h,inputsize)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mdcost_db_h\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdcost_dz_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-8d0b9a260f83>\u001b[0m in \u001b[0;36mmatrix_mult\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#col of b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#row of b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m               \u001b[0mprod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "nn = NeuralNetwork(input_size = INPUT_SIZE, hidden_nodes = HIDDEN_NODES, output_size = OUTPUT_SIZE)\n",
        "history = nn.fit(x_train, y_train, epochs=EPOCH, lr=LEARNING_RATE)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='Cross-entropy', title='Training Plot {}'.format(rollnumber));\n",
        "end = time.time()\n",
        "\n",
        "print(\"Runtime of the algorithm is \", round((end - start),3),\" seconds\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "group23_phase1_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "notify_time": "5",
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edfd44368ce34b0baaf8e0d1a018905b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbc7aed21cf344a8b62d533486c990d0",
              "IPY_MODEL_4b013811de1647f6a91b7b3f913d3f0f",
              "IPY_MODEL_45f90d00f99c4e06a5e976e8d45e1394"
            ],
            "layout": "IPY_MODEL_e638b9ca43874e5eae5d4b26118a4f54"
          }
        },
        "fbc7aed21cf344a8b62d533486c990d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35249f8243fb43e780bbe956c5205779",
            "placeholder": "​",
            "style": "IPY_MODEL_55388ce0810249ee92d46850aa5c3672",
            "value": "  0%"
          }
        },
        "4b013811de1647f6a91b7b3f913d3f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f920be710ea64966abf1455e7e61ed70",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4d9aa81c4064a27a984f06a41acb44a",
            "value": 0
          }
        },
        "45f90d00f99c4e06a5e976e8d45e1394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05dff9eb1af8463cbeb81d9b09e38997",
            "placeholder": "​",
            "style": "IPY_MODEL_7a79e130635c4179bdb65534881fabda",
            "value": " 0/1 [16:03&lt;?, ?it/s]"
          }
        },
        "e638b9ca43874e5eae5d4b26118a4f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35249f8243fb43e780bbe956c5205779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55388ce0810249ee92d46850aa5c3672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f920be710ea64966abf1455e7e61ed70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d9aa81c4064a27a984f06a41acb44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05dff9eb1af8463cbeb81d9b09e38997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a79e130635c4179bdb65534881fabda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}